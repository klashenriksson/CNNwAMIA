{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa4eab",
   "metadata": {},
   "source": [
    "# Assingment 2 - Tumor segmentation\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "Previously you have looked at the different available contrasts of the same anatomy, but the dataset also contains a manually segmented binary map of a tumor, if visible on the slice. For the second assignment your task is to create a tumor segmentation model that takes any number of image contrasts as an input, and outputs the tumor segmentations. For this task, you will implement and use the [DICE](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) score to evaluate (aim for a DICE score higher than $0.8$ on the validation set).\n",
    "\n",
    "Your task is to look through the highly customizable code below, which contains all the main steps for image segmentation from using only one contrast as an input. By changing the arrays of the DataGenerator, multiple contrasts can be added as input, similar as in Assignment 1. The most important issues with the current code are noted in the comments for easier comprehension. Your tasks, to include in the Jupyter notebook you hand in, are:\n",
    "- How you reached the required performances (DICE score above 0.8)\n",
    "- Plot the training/validating losses and accuracies. Describe when to stop training, and why that is a good choice.\n",
    "- Once you have reached the required loss on the validation data, and you have selected your final model, only then evaluate your model on the testing data as well.\n",
    "- Describe the thought process behind building your model and choosing the model hyper-parameters.\n",
    "- Describe what you think are the biggest issues with the provided network and training, and how you solved them.\n",
    "\n",
    "Upload the updated notebook to Canvas by March $31^{th}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2022)  # Set seed for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2022)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b60e2",
   "metadata": {},
   "source": [
    "##### The cell below will define the data generator for the data you will be using. You should not change anything in the below code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c238ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = []\n",
    "\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    arrays[idx][i, ] = x\n",
    "\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d606d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = \"/import/software/3ra023/vt22/brats/data/\"  # Change if you have copied the data locally on your machine \n",
    "array_labels = [\"t1\", \"mask\"]  # Available arrays are: 't1', 't1ce', 't2', 'flair', 'mask'.\n",
    "batch_size = 32\n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + \"training\",\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + \"validating\",\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + \"testing\",\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: What arrays are you using? You can use multiple contrasts as inputs, if you'd like.\n",
    "# NOTE: Which contrasts do you think are the best to use for tumor segmentation? Try plotting them all.\n",
    "# NOTE: What batch size are you using? Should you use more? Or less?\n",
    "# NOTE: Are you using the correct generators for the correct task? Training for training and validating for validating?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d757",
   "metadata": {},
   "source": [
    "### Let's plot some example images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e81cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig = plt.figure(figsize=(16.0, 8.0))\n",
    "fig.subplots_adjust(left=0.001,\n",
    "                    right=0.9975,\n",
    "                    top=0.95,\n",
    "                    bottom=0.005,\n",
    "                    wspace=0.05,\n",
    "                    hspace=0.14)\n",
    "\n",
    "M, N = 2, 4\n",
    "ax = []\n",
    "for i in range(M):\n",
    "    ax.append([None] * N)\n",
    "    for j in range(N):\n",
    "        ax[i][j] = plt.subplot2grid((M, N), (i, j), rowspan=1, colspan=1)\n",
    "\n",
    "imgs = gen_train[0]\n",
    "idx = [3, 7, 9, 14]  # Plot images in mini-batch with these indices\n",
    "ii = 0\n",
    "for j in range(N):\n",
    "    for i in range(M):\n",
    "        im = ax[i][j].imshow(imgs[i][idx[ii], :, :, 0], cmap='gray')\n",
    "\n",
    "        if j == 0:  # Label only on the left\n",
    "            ax[i][j].set_ylabel(gen_train.arrays[i], fontsize=22)\n",
    "        if j == N - 1:  # Colorbar only on the right\n",
    "            divider = make_axes_locatable(ax[i][j])\n",
    "            cax1 = divider.append_axes(\"right\", size=\"7%\", pad=0.05)\n",
    "            cbar = plt.colorbar(im, cax=cax1)\n",
    "    ii += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed09b7",
   "metadata": {},
   "source": [
    "A quick summary of the data sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images : {len(gen_train.file_list)}\")\n",
    "print(f\"Training batch size       : {gen_train.in_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff8008",
   "metadata": {},
   "source": [
    "### The dataset preprocessing so far has been to help you, you should not change anything above. However, from now on, take nothing for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages important for building and training your model.\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    filt_size = 2\n",
    "    input1 = Input(shape=(128, 128, 1))\n",
    "\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='zeros')(input1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='zeros')(pool1)\n",
    "    up1 = UpSampling2D(size = (2,2))(conv2)\n",
    "    conv3 = Conv2D(1, 3, activation='tanh', padding='same', kernel_initializer='zeros')(up1)\n",
    "    \n",
    "    return Model(inputs=[input1], outputs=conv3)\n",
    "\n",
    "# NOTE: Be inspired by the imported layers.\n",
    "# NOTE: Probably the most famous model architecture for segmentation is the U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e24a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your model.\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Do you have the correct number of input images?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Do you have the correct number of output images?\n",
    "# NOTE: What's the range of the output? Can you use an activation as a regularizer?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are your parameters split evenly inside the model? Try making \"too large\" layers smaller\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
    "    # Note that we want to maximise the Dice coefficient, but if you want to use it as a loss you need the negative\n",
    "    return -K.mean((2.0 * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "\n",
    "learning_rate = 0.0\n",
    "optim = optimizers.RMSprop(lr=learning_rate)\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=optim)\n",
    "\n",
    "# NOTE: Are you satisfied with the optimizer and its parameters?\n",
    "# NOTE: Try incorporating the DICE score into the model. Is it a loss function? Or a metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss = []\n",
    "    validating_loss = []\n",
    "    \n",
    "    for idx, (t1, mask) in enumerate(gen_train):\n",
    "        h = model.train_on_batch([t1], mask)\n",
    "        training_loss.append(h)\n",
    "    \n",
    "    for idx, (t1, mask) in enumerate(gen_val):\n",
    "        validating_loss.append(model.test_on_batch([t1], mask))\n",
    "        \n",
    "    print(np.mean(validating_loss))\n",
    "\n",
    "# NOTE: Plotting the losses helps a lot.\n",
    "# NOTE: What does plotting the training data tell you? Should you plot something else?\n",
    "# NOTE: What should one do with the validation data? The fit_generator has a 'validation_data' argument as well.\n",
    "# NOTE: When should one stop? Did you overtrain? Did you train for long enough?\n",
    "# NOTE: Think about implementing Early Stopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, mask = gen_val[np.random.randint(0, len(gen_val))]\n",
    "prediction = model.predict([t1])\n",
    "\n",
    "plt.figure(figsize=(8, 4*batch_size))\n",
    "for idx in range(batch_size):\n",
    "    plt.subplot(batch_size, 2, idx * 2 + 1)\n",
    "    plt.imshow(mask[idx, :, :], cmap='gray')\n",
    "    plt.title('GT', fontsize=22)\n",
    "    plt.subplot(batch_size, 2, idx * 2 + 2)\n",
    "    plt.imshow(prediction[idx, :, :], cmap='gray')\n",
    "    plt.title('PRED', fontsize=22)\n",
    "    \n",
    "# NOTE: What do the predictions mean? What values do they take?\n",
    "# NOTE: How can your predictions be used as masks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
