{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa4eab",
   "metadata": {},
   "source": [
    "# Assingment 3 - Contrast transfer\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "For radiotherapy treatment, often multiple contrasts are acquired of the same anatomy for better organ delineations. For the third assignment you are tasked to train a model transferring T1w MR images to a T2w contrast. If one could synthetically create additional contrasts, the patients wouldn't have to be scanned multiple times or for a long time, speeding up the scanning process.\n",
    "\n",
    "In this assignment, you will train a Conditional GAN model, discussed in the course lectures. A GAN has two models, a generator performing the actual task and a discriminator, learning the difference between real and generated images. The generator is trained to produce images that fool the discriminator, generating images that the discriminator think are real. Apart from the adversarial loss of the discriminator, you also have a paired pixel-wise loss in the conditional GAN model (like in the previous assignment). This improves learning. There is a weight balancing the two losses, denoted $\\alpha$ here.\n",
    "\n",
    "The task is to take T1-weighted images as inputs, and generate the corresponding T2-weighted images.\n",
    "\n",
    "The network architectures were the main focus in the previous two assignments, but here there is no need to change anything in the models. Although, you can change the models if you'd like. In fact, the only code you are tasked to change is in one cell, where the training parameters are defined (_e.g._, the learning rates, the optimizers, and the $\\alpha$). The generator has been modified here to return downsampled images, to make the training easier and faster.\n",
    "\n",
    "Your tasks, to include in the Jupyter notebook you hand in, are:\n",
    "- Reach a validation MSE below 0.015 on the validation set, and describe what parameter combinations you have gone through to reach those results.\n",
    "- The higher you set $\\alpha$, the easier the training will be, as the adversarial loss will have a lower effect. However, your should aim to minimize $\\alpha$ (note however that the lowest possible value of $\\alpha$ is 0).\n",
    "- If your final result is using $\\alpha > 0$, that means the requried MSE might be easy to achieve. In this case, aim to minimize the MSE even below the requried threshold, until your results \"look nice\".\n",
    "- The MSE threshold is a guideline, your main task is to describe the effect of each hyper-parameter you have changed, and the way you have experimented with them. What problems did you face? What happened when the training failed? Try describing everything that you have learnt.\n",
    "\n",
    "Upload the updated notebook to Canvas by June $3^{rd}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import random\n",
    "random.seed(2022)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2022)  # Set seed for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2022)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b60e2",
   "metadata": {},
   "source": [
    "##### The cell below will define the data generator for the data you will be using. You should not change anything in the below code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c238ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                im = zoom(im, 0.5)\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = []\n",
    "\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = zoom(x, 0.5)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    arrays[idx][i, ] = x\n",
    "\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!\n",
    "# NOTE: There is now a resizing part of the images, this is to make training easier and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d606d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = \"/import/software/3ra023/vt22/brats/data/\"  # Change if you have copied the data locally on your machine \n",
    "array_labels = [\"t1\", \"t2\"] \n",
    "batch_size = 32\n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + \"training\",\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + \"validating\",\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + \"testing\",\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: The task for this assignment is fixed. The input will be T1w images, and the output T2w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d757",
   "metadata": {},
   "source": [
    "### Let's plot some example images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e81cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig = plt.figure(figsize=(16.0, 8.0))\n",
    "fig.subplots_adjust(left=0.001,\n",
    "                    right=0.9975,\n",
    "                    top=0.95,\n",
    "                    bottom=0.005,\n",
    "                    wspace=0.05,\n",
    "                    hspace=0.14)\n",
    "\n",
    "M, N = 2, 4\n",
    "ax = []\n",
    "for i in range(M):\n",
    "    ax.append([None] * N)\n",
    "    for j in range(N):\n",
    "        ax[i][j] = plt.subplot2grid((M, N), (i, j), rowspan=1, colspan=1)\n",
    "\n",
    "imgs = gen_train[0]\n",
    "idx = np.random.randint(0, np.shape(gen_train[0][0])[0], 5)\n",
    "ii = 0\n",
    "for j in range(N):\n",
    "    for i in range(M):\n",
    "        im = ax[i][j].imshow(imgs[i][idx[ii], :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "        if j == 0:  # Label only on the left\n",
    "            ax[i][j].set_ylabel(gen_train.arrays[i], fontsize=22)\n",
    "        if j == N - 1:  # Colorbar only on the right\n",
    "            divider = make_axes_locatable(ax[i][j])\n",
    "            cax1 = divider.append_axes(\"right\", size=\"7%\", pad=0.05)\n",
    "            cbar = plt.colorbar(im, cax=cax1)\n",
    "    ii += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed09b7",
   "metadata": {},
   "source": [
    "A quick summary of the data sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images : {len(gen_train.file_list)}\")\n",
    "print(f\"Training batch size       : {gen_train.in_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff8008",
   "metadata": {},
   "source": [
    "### The dataset preprocessing so far has been to help you, you should not change anything above. However, from now on, take nothing for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages important for building and training your model.\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, UpSampling2D, Conv2DTranspose, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator(in_shape=(64,64,1)):\n",
    "    num_filt = 4\n",
    "    inputs = Input(in_shape)\n",
    "    conv1 = Conv2D(num_filt, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(num_filt, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(num_filt * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(num_filt * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(num_filt * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(num_filt * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(num_filt * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(num_filt * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(num_filt * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(num_filt * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(num_filt * 8, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis=3)\n",
    "    conv6 = Conv2D(num_filt * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(num_filt * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(num_filt * 4, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis=3)\n",
    "    conv7 = Conv2D(num_filt * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(num_filt * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(num_filt * 2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis=3)\n",
    "    conv8 = Conv2D(num_filt * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(num_filt * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(num_filt, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis=3)\n",
    "    conv9 = Conv2D(num_filt, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(num_filt, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation=relu_range)(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    return model\n",
    "\n",
    "# NOTE: The generator is a U-Net with 4 down- and upsampling layers. Maybe similar to what you have used in Assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def relu_range(x): # A custom made activation layer used on the output. Can you figure out what it does? And why it's better than the alternatives?\n",
    "    x = tensorflow.where(K.greater(x, 0), x, K.zeros_like(x))\n",
    "    x = tensorflow.where(K.less(x, 1), x, K.ones_like(x))\n",
    "    return x\n",
    "    \n",
    "def build_discriminator(in_shape=(64,64,1)):\n",
    "    num_filt = 4\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filt, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(num_filt * 2, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(num_filt * 4, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(num_filt * 8, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(num_filt * 16, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(num_filt * 32, (3,3), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation=relu_range))\n",
    "    return model\n",
    "\n",
    "# NOTE: The discriminator is a simple convolutional model with continuous downsampling. Maybe similar to what you have used in Assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ec4db",
   "metadata": {},
   "source": [
    "## The below cell is all the code you are asked to modify. Change the learning rates, alpha and the optimizers to achieve the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17124be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_dis = 0.01\n",
    "learning_rate_GAN = 0.01\n",
    "alpha = 0.5\n",
    "\n",
    "opt_gan = Adam(lr=learning_rate_GAN, beta_1=0.5)\n",
    "opt_dis = Adam(lr=learning_rate_dis, beta_1=0.5)\n",
    "\n",
    "# NOTE: Describe your choices. Aim for the lowest alpha you can achieve (the lowest value is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()  \n",
    "\n",
    "generator.compile(loss=\"mse\")\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=opt_dis, metrics=['accuracy'])\n",
    "\n",
    "# GAN\n",
    "discriminator.trainable = False\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "inp = Input(shape=(64,64,1))\n",
    "pred = generator(inp)\n",
    "labels = discriminator(pred)\n",
    "GAN = Model(inputs=inp, outputs=[labels, pred])\n",
    "GAN.summary()\n",
    "\n",
    "GAN.compile(loss='binary_crossentropy', loss_weights=[1, alpha], optimizer=opt_gan)\n",
    "\n",
    "# NOTE: The GAN has roughly the same number of non-trainable and trainable parameters, meaning the generator and the discriminator have roughly the same complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "real_label = np.ones((batch_size, 1))\n",
    "fake_label = np.zeros((batch_size, 1))\n",
    "\n",
    "plot_val_loss = []\n",
    "plot_train_dis_loss = []\n",
    "plot_train_gan_loss = []\n",
    "plot_val_dis_real = []\n",
    "plot_val_dis_fake = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss_dis = []\n",
    "    training_loss_GAN = []\n",
    "    validating_loss = []\n",
    "    validating_dis_real = []\n",
    "    validating_dis_fake = []\n",
    "    \n",
    "    for idx, (t1, t2) in enumerate(gen_train):\n",
    "        pred = generator.predict_on_batch(t1)\n",
    "        h_dis = discriminator.train_on_batch(np.concatenate((t2, pred)), np.concatenate((real_label, fake_label)))\n",
    "        training_loss_dis.append(h_dis)\n",
    "                                            \n",
    "        h_gan = GAN.train_on_batch(t1, [real_label, t2])\n",
    "        training_loss_GAN.append(h_gan)\n",
    "    \n",
    "    plot_train_dis_loss.append(np.mean(training_loss_dis))\n",
    "    plot_train_gan_loss.append(np.mean(training_loss_GAN))\n",
    "    \n",
    "    \n",
    "    for idx, (t1, t2) in enumerate(gen_val):\n",
    "        h_dis = discriminator.test_on_batch(t2, real_label)\n",
    "        validating_dis_real.append(h_dis[1])\n",
    "        h_dis = discriminator.test_on_batch(generator.predict(t1), fake_label)\n",
    "        validating_dis_fake.append(h_dis[1])\n",
    "        \n",
    "        validating_loss.append(generator.test_on_batch(t1, t2))\n",
    "        \n",
    "    \n",
    "    plot_val_dis_real.append(np.mean(validating_dis_real))\n",
    "    plot_val_dis_fake.append(np.mean(validating_dis_fake))\n",
    "    plot_val_loss.append(np.mean(validating_loss))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"Epoch \" + str(epoch) + \", validation loss: \" + str(np.mean(validating_loss))[:6])\n",
    "    fig, axs = plt.subplots(1,3,figsize=(16,8))\n",
    "    axs[0].plot(np.linspace(0, epoch, epoch + 1), plot_train_dis_loss, label=\"dis_loss\")\n",
    "    axs[0].plot(np.linspace(0, epoch, epoch + 1), plot_train_gan_loss, label=\"gan_loss\")\n",
    "    axs[0].set_title(\"Training loss\")\n",
    "    axs[0].grid(True)\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(loc='lower left')\n",
    "    if ((np.mean(training_loss_dis) < 1.0) & (np.mean(training_loss_GAN) < 1.0)):\n",
    "        axs[0].set_ylim([0, 2])\n",
    "    \n",
    "    \n",
    "    \n",
    "    axs[1].plot(np.linspace(0, epoch, epoch + 1), plot_val_dis_real, label=\"real\")\n",
    "    axs[1].plot(np.linspace(0, epoch, epoch + 1), plot_val_dis_fake, label=\"fake\")\n",
    "    axs[1].set_title(\"Discriminator performance (accuracy)\")\n",
    "    axs[1].grid(True)\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(loc='lower left')\n",
    "    \n",
    "    axs[2].plot(np.linspace(0, epoch, epoch + 1), plot_val_loss)\n",
    "    axs[2].set_title(\"Validation performance (MSE)\")\n",
    "    axs[2].grid(True)\n",
    "    axs[2].set_xlabel('Epoch')\n",
    "    if (np.mean(validating_loss) < 0.05):\n",
    "        axs[2].set_ylim([0, 0.1])\n",
    "    plt.show()\n",
    "    \n",
    "    # if (np.mean(validating_loss) < 0.015):\n",
    "    #     break\n",
    "\n",
    "# NOTE: Describe what behavior you expect from the three plots?\n",
    "# NOTE: Detail what outcomes you have faced when the training failed? Why do you think that happened? How did you try to fix it?\n",
    "# NOTE: How long did training take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2 = gen_val[np.random.randint(0, len(gen_val))]\n",
    "prediction = generator.predict(t1)\n",
    "plt.figure(figsize=(8, 4 * batch_size))\n",
    "for idx in range(batch_size):\n",
    "    plt.subplot(batch_size, 3, idx * 3 + 1)\n",
    "    plt.imshow(t1[idx, :, :], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title('Image', fontsize=22)\n",
    "    plt.subplot(batch_size, 3, idx * 3 + 2)\n",
    "    plt.imshow(t2[idx, :, :], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title('GT', fontsize=22)\n",
    "    plt.subplot(batch_size, 3, idx * 3 + 3)\n",
    "    plt.imshow(prediction[idx, :, :], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title('PRED', fontsize=22)\n",
    "\n",
    "# NOTE: How good do the images look like? What do you think is needed for better results?\n",
    "# NOTE: Did you use alpha = 0? Describe the difficulty of balancing the two learning rates! Does that become easier by increasing alpha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4034754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_loss = []\n",
    "# for idx, (t1, t2) in enumerate(gen_test):\n",
    "#     testing_loss.append(generator.test_on_batch(t1, t2))\n",
    "# print(np.mean(testing_loss))\n",
    "\n",
    "# NOTE: Only evaluate the testing set, when you are not changing the code anymore.\n",
    "# NOTE: How different is the performance on the validation and testing sets?\n",
    "# NOTE: Do your results speak of overfitting? Underfitting?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
